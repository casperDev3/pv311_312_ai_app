import torch
from diffusers import DiffusionPipeline
import os
import time
from PIL import Image
import numpy as np

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –º–æ–¥–µ–ª—å, —è–∫–∞ –ø—ñ–¥—Ç—Ä–∏–º—É—î safetensors
MODEL_ID = "damo-vilab/text-to-video-ms-1.7b"
MODEL_CACHE_DIR = "./models/video-diffusion"


def download_model():
    print("=" * 20)
    print("Downloading Video Diffusion model...")

    os.makedirs(MODEL_CACHE_DIR, exist_ok=True)

    try:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        pipe = DiffusionPipeline.from_pretrained(
            MODEL_ID,
            cache_dir=MODEL_CACHE_DIR,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            safety_checker=None,
            use_safetensors=True,
            low_cpu_mem_usage=True
        )

        save_path = os.path.join(MODEL_CACHE_DIR, "saved_model")
        pipe.save_pretrained(save_path)

        print(f"Model downloaded and saved to {save_path}")
        return True
    except Exception as e:
        print(f"Error downloading model: {e}")
        return False


def load_model():
    print("=" * 20)
    print("Loading Video Diffusion model from cache...")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    try:
        pipe = DiffusionPipeline.from_pretrained(
            os.path.join(MODEL_CACHE_DIR, "saved_model"),
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            safety_checker=None,
            low_cpu_mem_usage=True
        ).to(device)

        if device == "cuda":
            pipe.enable_attention_slicing()
            if hasattr(pipe, 'enable_vae_slicing'):
                pipe.enable_vae_slicing()

        return pipe
    except Exception as e:
        print(f"Error loading model: {e}")
        return None


def extract_frames_simple(result):
    """–ü—Ä–æ—Å—Ç–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤ –∑ TextToVideoSDPipelineOutput"""
    try:
        print(f"Result type: {type(result)}")

        # –ë–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—ñ–π –¥–æ—Å—Ç—É–ø –¥–æ frames –∞—Ç—Ä–∏–±—É—Ç—É
        if hasattr(result, 'frames'):
            frames_array = result.frames
            print(f"Frames array type: {type(frames_array)}")
            print(f"Frames array shape: {frames_array.shape}")

            # frames_array –º–∞—î —Ñ–æ—Ä–º—É: (batch_size, num_frames, height, width, channels)
            # –ó–∞–∑–≤–∏—á–∞–π: (1, 16, 256, 256, 3) –∞–±–æ –ø–æ–¥—ñ–±–Ω—É

            if len(frames_array.shape) == 5:
                # –í–∏–¥–∞–ª—è—î–º–æ batch dimension —ñ –æ—Ç—Ä–∏–º—É—î–º–æ (num_frames, height, width, channels)
                frames_array = frames_array[0]
                print(f"After removing batch dimension: {frames_array.shape}")

            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –∫–æ–∂–µ–Ω –∫–∞–¥—Ä –≤ PIL Image
            frames = []
            for i in range(frames_array.shape[0]):
                frame = frames_array[i]

                # –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—è, —â–æ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ [0, 255]
                if frame.max() <= 1.0:
                    frame = (frame * 255).astype(np.uint8)
                else:
                    frame = frame.astype(np.uint8)

                # –°—Ç–≤–æ—Ä—é—î–º–æ PIL Image
                pil_img = Image.fromarray(frame)
                frames.append(pil_img)

            print(f"Successfully converted {len(frames)} frames to PIL images")
            return frames
        else:
            print("No 'frames' attribute found in result")
            print(f"Available attributes: {[attr for attr in dir(result) if not attr.startswith('_')]}")
            return None

    except Exception as e:
        print(f"Error in extract_frames_simple: {e}")
        import traceback
        traceback.print_exc()
        return None


def generate_video(pipe, prompt, out_path=None, num_frames=16, steps=30, guidance=7.5, fps=8):
    print("=" * 20)
    print(f"Generating video for prompt: {prompt}")
    print(f"Frames: {num_frames}, FPS: {fps}")

    try:
        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–µ–æ
        result = pipe(
            prompt,
            num_inference_steps=steps,
            guidance_scale=guidance,
            num_frames=num_frames
        )

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤ –ø—Ä–æ—Å—Ç–æ—é —Ñ—É–Ω–∫—Ü—ñ—î—é
        video_frames = extract_frames_simple(result)

        if not video_frames:
            print("Failed to extract frames")
            return None

        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        os.makedirs("generated_videos", exist_ok=True)

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        if out_path is None:
            timestamp = int(time.time())
            out_path = f"generated_videos/video_{timestamp}.gif"

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫ GIF
        if len(video_frames) > 0:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä–∏ –ø–µ—Ä—à–æ–≥–æ –∫–∞–¥—Ä—É
            print(f"First frame size: {video_frames[0].size}")
            print(f"First frame mode: {video_frames[0].mode}")

            video_frames[0].save(
                out_path,
                save_all=True,
                append_images=video_frames[1:],
                duration=1000 // fps,  # –º—ñ–ª—ñ—Å–µ–∫—É–Ω–¥–∏ –Ω–∞ –∫–∞–¥—Ä
                loop=0,
                optimize=True
            )
            print(f"‚úÖ GIF video saved to {out_path}")
            print(f"‚úÖ Generated {len(video_frames)} frames")

            return video_frames
        else:
            print("‚ùå Error: No frames in video_frames list")
            return None

    except Exception as e:
        print(f"‚ùå Error during video generation: {e}")
        import traceback
        traceback.print_exc()
        return None


def save_video_as_mp4(frames, out_path, fps=8):
    """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫ MP4"""
    try:
        import cv2

        if not isinstance(frames, list) or len(frames) == 0:
            print("No frames to save as MP4")
            return

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è PIL images –¥–æ numpy array
        frames_np = [np.array(frame) for frame in frames]

        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—ñ–≤ –≤—ñ–¥–µ–æ
        height, width = frames_np[0].shape[:2]
        print(f"Video dimensions: {width}x{height}")

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è VideoWriter
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

        for frame in frames_np:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è RGB –¥–æ BGR –¥–ª—è OpenCV
            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            out.write(frame_bgr)

        out.release()
        print(f"‚úÖ MP4 video saved to {out_path}")

    except ImportError:
        print("‚ùå OpenCV not available. Install with: pip install opencv-python")
    except Exception as e:
        print(f"‚ùå Error saving MP4: {e}")


def debug_model_output(pipe, prompt):
    """–§—É–Ω–∫—Ü—ñ—è –¥–ª—è –¥–µ–±–∞–≥—ñ–Ω–≥—É –≤–∏–≤–æ–¥—É –º–æ–¥–µ–ª—ñ"""
    print("=" * 20)
    print("DEBUG: Testing model output...")

    try:
        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä—É –¥–ª—è —Ç–µ—Å—Ç—É
        result = pipe(
            prompt,
            num_inference_steps=5,  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–ª—è —Ç–µ—Å—Ç—É
            num_frames=4
        )

        print("DEBUG: Result analysis:")
        print(f"  Type: {type(result)}")
        print(f"  Attributes: {[attr for attr in dir(result) if not attr.startswith('_')]}")

        if hasattr(result, 'frames'):
            frames = result.frames
            print(f"  Frames type: {type(frames)}")
            print(f"  Frames shape: {frames.shape}")
            print(f"  Frames dtype: {frames.dtype}")
            print(f"  Frames range: [{frames.min()}, {frames.max()}]")

            # –°–ø—Ä–æ–±—É—î–º–æ –∑–±–µ—Ä–µ–≥—Ç–∏ –ø–µ—Ä—à–∏–π –∫–∞–¥—Ä —è–∫ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
            if len(frames.shape) >= 4:
                test_frame = frames[0, 0] if len(frames.shape) == 5 else frames[0]
                if test_frame.max() <= 1.0:
                    test_frame = (test_frame * 255).astype(np.uint8)
                test_img = Image.fromarray(test_frame)
                test_img.save("debug_test_frame.jpg")
                print("  ‚úÖ Debug frame saved as debug_test_frame.jpg")

        return True
    except Exception as e:
        print(f"DEBUG Error: {e}")
        return False


def main():
    prompt = "A astronaut riding a horse on mars"

    try:
        pipe = load_model()

        if pipe is None:
            print("‚ùå Failed to load model")
            return

        # –°–ø–æ—á–∞—Ç–∫—É –∑–∞–ø—É—Å—Ç–∏–º–æ –¥–µ–±–∞–≥
        debug_model_output(pipe, prompt)

        print("=" * 20)
        print("Starting video generation...")

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–µ–æ
        frames = generate_video(
            pipe,
            prompt,
            num_frames=8,  # –ú–µ–Ω—à–µ –∫–∞–¥—Ä—ñ–≤ –¥–ª—è —à–≤–∏–¥—à–æ—ó –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
            steps=200,  # –ú–µ–Ω—à–µ –∫—Ä–æ–∫—ñ–≤
            guidance=7.5,
            fps=4
        )

        if frames:
            # –î–æ–¥–∞—Ç–∫–æ–≤–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫ MP4
            timestamp = int(time.time())
            mp4_path = f"generated_videos/video_{timestamp}.mp4"
            save_video_as_mp4(frames, mp4_path, fps=4)
            print("üéâ Video generation completed successfully!")
        else:
            print("‚ùå Video generation failed - no frames produced")

    except Exception as e:
        print(f"‚ùå Video generation failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –º–æ–¥–µ–ª—å –≤–∂–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞
    if os.path.exists(os.path.join(MODEL_CACHE_DIR, "saved_model")):
        print("Model found in cache, skipping download...")
        main()
    else:
        print("Downloading model...")
        if download_model():
            print("Model downloaded successfully!")
            main()
        else:
            print("Failed to download model")