import cv2
import numpy as np
import time
import os
from pathlib import Path
import face_recognition
import traceback
from ultralytics import YOLO
import threading


class FrameGrabber(threading.Thread):
    """–ü–æ—Ç—ñ–∫ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∑—á–∏—Ç—É–≤–∞–Ω–Ω—è –∫–∞–¥—Ä—ñ–≤ –∑ –∫–∞–º–µ—Ä–∏"""
    def __init__(self, src=0, width=1920, height=1080):
        super().__init__()
        self.capture = cv2.VideoCapture(src)
        self.capture.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        self.lock = threading.Lock()
        self.latest_frame = None
        self.running = True
        if not self.capture.isOpened():
            raise RuntimeError("–ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏ –∫–∞–º–µ—Ä—É!")

    def run(self):
        while self.running:
            ret, frame = self.capture.read()
            if not ret:
                continue
            with self.lock:
                self.latest_frame = frame

    def read(self):
        """–ü–æ–≤–µ—Ä—Ç–∞—î –æ—Å—Ç–∞–Ω–Ω—ñ–π –¥–æ—Å—Ç—É–ø–Ω–∏–π –∫–∞–¥—Ä"""
        with self.lock:
            frame_copy = self.latest_frame.copy() if self.latest_frame is not None else None
        return frame_copy

    def stop(self):
        self.running = False
        self.capture.release()


class FaceRecognitionSystem:
    def __init__(self):
        self.known_faces_encodings = []
        self.known_faces_names = []
        self.face_locations = []
        self.face_encodings = []
        self.face_names = []
        self.people_boxes = []
        self.phone_boxes = []

        print("üß† –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ YOLOv8n –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –ª—é–¥–µ–π...")
        self.person_detector = YOLO("yolov8n.pt")
        self.person_detector.to("cuda" if cv2.cuda.getCudaEnabledDeviceCount() > 0 else "cpu")

        self.frame_count = 0
        self.lock = threading.Lock()

    def load_known_faces(self, photo_folder="photos"):
        print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ—ñ–π –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è...")
        if not os.path.exists(photo_folder):
            print(f"!!! –ü–∞–ø–∫–∞ –Ω–µ —ñ—Å–Ω—É—î {photo_folder}")
            return False

        person_folders = [f for f in Path(photo_folder).iterdir() if f.is_dir()]
        if not person_folders:
            print(f"–ù–µ–º–∞—î –ø—ñ–¥–ø–∞–ø–æ–∫ –∑ –ø—Ä–∞—Ü—ñ–≤–Ω–∏–∫–∞–º–∏ —É {photo_folder}")
            return False

        total_photos = 0
        for person_folder in person_folders:
            person_name = person_folder.name
            photo_files = list(person_folder.glob("*.jpg")) + list(person_folder.glob("*.jpeg")) + list(person_folder.glob("*.png"))
            for photo_path in photo_files:
                try:
                    image = face_recognition.load_image_file(str(photo_path))
                    enc = face_recognition.face_encodings(image)
                    if len(enc) == 0:
                        continue
                    self.known_faces_encodings.append(enc[0])
                    self.known_faces_names.append(person_name)
                    total_photos += 1
                except Exception as err:
                    print("–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ:", err)
        print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_photos} —Ñ–æ—Ç–æ –æ–±–ª–∏—á")
        return total_photos > 0

    def process_frame(self, frame, face_interval=1, scale_factor=0.25):
        """–§–æ–Ω–æ–≤–∞ –æ–±—Ä–æ–±–∫–∞ –∫–∞–¥—Ä—É ‚Äî –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –≤ –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ"""
        people_boxes = []
        phone_boxes = []

        # YOLO –Ω–∞ –∑–º–µ–Ω—à–µ–Ω–æ–º—É –∫–∞–¥—Ä—ñ
        small_for_yolo = cv2.resize(frame, (640, 360))
        results = self.person_detector.predict(small_for_yolo, classes=[0, 67], conf=0.5, verbose=False)
        for r in results:
            for box in r.boxes:
                if box.cls == 0:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    h_ratio = frame.shape[0] / 360
                    w_ratio = frame.shape[1] / 640
                    people_boxes.append((int(x1 * w_ratio), int(y1 * h_ratio), int(x2 * w_ratio), int(y2 * h_ratio)))
                elif box.cls  == 67:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    h_ratio = frame.shape[0] / 360
                    w_ratio = frame.shape[1] / 640
                    phone_boxes.append((int(x1 * w_ratio), int(y1 * h_ratio), int(x2 * w_ratio), int(y2 * h_ratio)))

        # Face Recognition –Ω–µ –∫–æ–∂–µ–Ω –∫–∞–¥—Ä
        if self.frame_count % face_interval == 0:
            small_frame = cv2.resize(frame, (0, 0), fx=scale_factor, fy=scale_factor)
            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
            face_locations = face_recognition.face_locations(rgb_small_frame)
            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

            face_names = []
            for face_encoding in face_encodings:
                matches = face_recognition.compare_faces(self.known_faces_encodings, face_encoding, tolerance=0.6)
                name = "Unknown"
                confidence = 0
                face_distances = face_recognition.face_distance(self.known_faces_encodings, face_encoding)
                if len(face_distances) > 0:
                    best_match_index = np.argmin(face_distances)
                    if matches[best_match_index]:
                        name = self.known_faces_names[best_match_index]
                        confidence = (1 - face_distances[best_match_index]) * 100
                face_names.append((name, confidence))

            face_locations = [
                (int(t / scale_factor), int(r / scale_factor), int(b / scale_factor), int(l / scale_factor))
                for (t, r, b, l) in face_locations
            ]

            # –ë–µ–∑–ø–µ—á–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø—ñ–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö
            with self.lock:
                self.face_locations = face_locations
                self.face_names = face_names

        # –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É —Ç—ñ–ª
        with self.lock:
            self.people_boxes = people_boxes
            self.phone_boxes = phone_boxes

        self.frame_count += 1

    def draw_results(self, frame):
        with self.lock:
            people_boxes = self.people_boxes.copy()
            face_locations = self.face_locations.copy()
            face_names = self.face_names.copy()

        for (x1, y1, x2, y2) in people_boxes:
            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 200, 0), 2)
            cv2.putText(frame, "Person", (x1, y1 - 8),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 0), 2)

        for (x1, y1, x2, y2)  in self.phone_boxes:
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 200, 255), 2)
            cv2.putText(frame, "Phone", (x1, y1 - 8),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 200, 255), 2)

        for (top, right, bottom, left), (name, confidence) in zip(face_locations, face_names):
            # –Ø–∫—â–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –æ–±–ª–∏—á—á—è –≤–∏—Ö–æ–¥—è—Ç—å –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —Ç–æ –ø—ñ–¥—Å–≤—á—É—î–º–æ —á–µ—Ä–≤–æ–Ω–∏–º —Ä–∞–º–∫—É
            face_box_color = (0, 255, 0)
            for (px1, py1, px2, py2) in self.phone_boxes:
                if left < px2 and right > px1 and top < py2 and bottom > py1:
                    face_box_color = (0, 0, 255)
                    break
            cv2.rectangle(frame, (left, top), (right, bottom), face_box_color, 2)
            cv2.putText(frame, f"{name} ({confidence:.1f}%)", (left, top - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, face_box_color, 2)


def run_face_recognition(camera_id=0, photos_folder="photos"):
    system = FaceRecognitionSystem()
    if not system.load_known_faces(photos_folder):
        print("–ù–µ –≤–¥–∞–ª–æ—Å—å –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –æ–±–ª–∏—á—á—è!")
        return

    grabber = FrameGrabber(camera_id)
    grabber.start()

    print("üöÄ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –æ–±–ª–∏—á —ñ —Ç—ñ–ª –∑–∞–ø—É—â–µ–Ω–æ!")

    fps_start = time.time()
    fps_counter = 0
    fps = 0

    process_thread = None

    try:
        while True:
            frame = grabber.read()
            if frame is None:
                continue

            # –Ø–∫—â–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–æ—Ç—ñ–∫ –∑–∞–≤–µ—Ä—à–∏–≤—Å—è ‚Äî –∑–∞–ø—É—Å–∫–∞—î–º–æ –Ω–æ–≤–∏–π –¥–ª—è –æ–±—Ä–æ–±–∫–∏
            if process_thread is None or not process_thread.is_alive():
                process_thread = threading.Thread(target=system.process_frame, args=(frame,))
                process_thread.start()

            # –ú–∞–ª—é—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            system.draw_results(frame)

            # FPS
            fps_counter += 1
            if time.time() - fps_start >= 1:
                fps = fps_counter
                fps_counter = 0
                fps_start = time.time()

            cv2.rectangle(frame, (5, 5), (120, 35), (0, 0, 0), -1)
            cv2.putText(frame, f"FPS: {fps}", (10, 25),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            cv2.imshow("Heimdall ‚Äî Async Face+Body Detection", frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        print("üõë –ó—É–ø–∏–Ω–µ–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    finally:
        grabber.stop()
        grabber.join()
        cv2.destroyAllWindows()


if __name__ == "__main__":
    try:
        run_face_recognition(camera_id=0, photos_folder="photos")
    except Exception as e:
        print("‚ùå –ü–æ–º–∏–ª–∫–∞:", e)
        traceback.print_exc()
