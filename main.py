"""
üß† –ü–†–û–°–¢–ò–ô –ü–ï–†–¶–ï–ü–¢–†–û–ù –ó –ù–£–õ–Ø
–ê–≤—Ç–æ—Ä: Igorich
–ú–µ—Ç–∞: –ù–∞–≤—á–∏—Ç–∏ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞—Ç–∏, —á–∏ –ª–µ–∂–∏—Ç—å —Ç–æ—á–∫–∞ (x, y)
      –≤–∏—â–µ –∞–±–æ –Ω–∏–∂—á–µ –¥—ñ–∞–≥–æ–Ω–∞–ª—ñ y = x.
–ú–æ–≤–∞: Python 3
–ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∏: numpy, matplotlib

üß© –©–æ –±—É–¥–µ –∑—Ä–æ–±–ª–µ–Ω–æ:
1. –ó–≥–µ–Ω–µ—Ä—É—î–º–æ –¥–∞–Ω—ñ (—Ç–æ—á–∫–∏)
2. –†–µ–∞–ª—ñ–∑—É—î–º–æ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω –∑ –Ω—É–ª—è
3. –ù–∞–≤—á–∏–º–æ –π–æ–≥–æ –∫–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏
4. –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
"""
import numpy as np
import matplotlib.pyplot as plt
import random

def generate_data(n=1000):
    X = np.random.uniform(-1, 1, (n, 2))
    y = np.array([1 if x[1] > x[0] else 0 for x in X])
    return X, y

class Perceptron:
    def __init__(self, input_size, learning_rate=0.01, epochs=50):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω–∞.
        :param input_size:  - —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—å –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö (–∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫)
        :param learning_rate: - —à–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è
        :param epochs:  - –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö –Ω–∞–≤—á–∞–Ω–Ω—è
        """
        self.lr = learning_rate
        self.epochs = epochs
        self.weights = np.zeros(input_size + 1)  # +1 –¥–ª—è –∑—Å—É–≤—É (bias)

    def activation(self,  x):
        return np.where(x >= 0, 1, 0) # Softmax –∞–∫—Ç–∏–≤–∞—Ü—ñ—è

    def predict(self, x):
        x_with_bias = np.insert(x, 0, 1) # –î–æ–¥–∞—î–º–æ –∑—Å—É–≤
        z = np.dot(self.weights, x_with_bias) # –õ—ñ–Ω—ñ–π–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è
        return self.activation(z)

def main():
    data = generate_data(100)
    X, y = data
    perceptron = Perceptron(input_size=2, learning_rate=0.1, epochs=20)
    print(data)

if __name__ == "__main__":
    main()